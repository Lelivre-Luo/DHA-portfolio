// This file is auto-generated. Do not edit manually.
// Run 'pnpm run build:content' to regenerate.

export type BlogPost = {
  id: number
  title: string
  excerpt: string
  date: string
  readTime: string
  slug: string
  tags: string[]
  image?: string | null
  content?: string
}

export const allBlogPosts: BlogPost[] = [
  {
    "id": 1,
    "title": "GraphQL vs REST in Python Backend Applications",
    "excerpt": "An in-depth comparison of GraphQL and REST API approaches in Python backend applications, with real-world examples and performance considerations.",
    "date": "January 22, 2023",
    "readTime": "8 min read",
    "image": null,
    "slug": "graphql-vs-rest-python",
    "tags": [
      "GraphQL",
      "REST API",
      "Python",
      "Backend"
    ],
    "content": "<h1>GraphQL vs REST in Python Backend Applications</h1>\n<p>When building modern web applications, choosing between GraphQL and REST APIs is a crucial decision that affects your application's architecture, performance, and developer experience. This comprehensive guide compares both approaches in the context of Python backend development.</p>\n<h2>Understanding REST APIs</h2>\n<p>REST (Representational State Transfer) is an architectural style that uses HTTP methods to perform operations on resources. It's been the standard for web APIs for many years.</p>\n<h3>REST Characteristics</h3>\n<ul>\n<li><strong>Resource-based</strong>: URLs represent resources</li>\n<li><strong>HTTP methods</strong>: GET, POST, PUT, DELETE for different operations</li>\n<li><strong>Stateless</strong>: Each request contains all necessary information</li>\n<li><strong>Cacheable</strong>: Responses can be cached</li>\n<li><strong>Uniform interface</strong>: Consistent API design</li>\n</ul>\n<h3>Python REST Implementation with FastAPI</h3>\n<pre><code class=\"language-python\">from fastapi import FastAPI, HTTPException\r\nfrom pydantic import BaseModel\r\nfrom typing import List, Optional\r\n\r\napp = FastAPI()\r\n\r\nclass User(BaseModel):\r\n    id: int\r\n    name: str\r\n    email: str\r\n    age: Optional[int] = None\r\n\r\nclass Post(BaseModel):\r\n    id: int\r\n    title: str\r\n    content: str\r\n    author_id: int\r\n\r\n# REST endpoints\r\n@app.get(\"/users\", response_model=List[User])\r\nasync def get_users(skip: int = 0, limit: int = 10):\r\n    # Return list of users\r\n    pass\r\n\r\n@app.get(\"/users/{user_id}\", response_model=User)\r\nasync def get_user(user_id: int):\r\n    # Return specific user\r\n    pass\r\n\r\n@app.get(\"/users/{user_id}/posts\", response_model=List[Post])\r\nasync def get_user_posts(user_id: int):\r\n    # Return posts for specific user\r\n    pass\r\n\r\n@app.post(\"/users\", response_model=User)\r\nasync def create_user(user: User):\r\n    # Create new user\r\n    pass\n</code></pre>\n<h2>Understanding GraphQL</h2>\n<p>GraphQL is a query language and runtime for APIs that allows clients to request exactly the data they need. It was developed by Facebook and provides a more flexible approach to data fetching.</p>\n<h3>GraphQL Characteristics</h3>\n<ul>\n<li><strong>Single endpoint</strong>: All queries go to one endpoint</li>\n<li><strong>Client-specified queries</strong>: Clients define what data they want</li>\n<li><strong>Strongly typed</strong>: Schema defines the API structure</li>\n<li><strong>Real-time subscriptions</strong>: Built-in support for real-time updates</li>\n<li><strong>Introspection</strong>: Self-documenting API</li>\n</ul>\n<h3>Python GraphQL Implementation with Strawberry</h3>\n<pre><code class=\"language-python\">import strawberry\r\nfrom strawberry.fastapi import GraphQLRouter\r\nfrom typing import List, Optional\r\n\r\n@strawberry.type\r\nclass User:\r\n    id: int\r\n    name: str\r\n    email: str\r\n    age: Optional[int] = None\r\n    posts: List['Post'] = strawberry.field(default_factory=list)\r\n\r\n@strawberry.type\r\nclass Post:\r\n    id: int\r\n    title: str\r\n    content: str\r\n    author: User\r\n\r\n@strawberry.type\r\nclass Query:\r\n    @strawberry.field\r\n    def users(self, skip: int = 0, limit: int = 10) -> List[User]:\r\n        # Return list of users\r\n        pass\r\n    \r\n    @strawberry.field\r\n    def user(self, user_id: int) -> Optional[User]:\r\n        # Return specific user\r\n        pass\r\n\r\n@strawberry.type\r\nclass Mutation:\r\n    @strawberry.mutation\r\n    def create_user(self, name: str, email: str, age: Optional[int] = None) -> User:\r\n        # Create new user\r\n        pass\r\n\r\nschema = strawberry.Schema(query=Query, mutation=Mutation)\r\ngraphql_app = GraphQLRouter(schema)\r\napp.include_router(graphql_app, prefix=\"/graphql\")\n</code></pre>\n<h2>Detailed Comparison</h2>\n<h3>1. Data Fetching</h3>\n<p><strong>REST Approach:</strong></p>\n<pre><code class=\"language-python\"># Multiple requests needed\r\nGET /users/1\r\nGET /users/1/posts\r\nGET /users/1/posts/1/comments\n</code></pre>\n<p><strong>GraphQL Approach:</strong></p>\n<pre><code class=\"language-graphql\">query {\r\n  user(id: 1) {\r\n    name\r\n    email\r\n    posts {\r\n      title\r\n      content\r\n      comments {\r\n        text\r\n        author {\r\n          name\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\n</code></pre>\n<h3>2. Over-fetching and Under-fetching</h3>\n<p><strong>REST Problems:</strong></p>\n<ul>\n<li><strong>Over-fetching</strong>: Getting more data than needed</li>\n<li><strong>Under-fetching</strong>: Not getting enough data, requiring multiple requests</li>\n</ul>\n<p><strong>GraphQL Solution:</strong></p>\n<ul>\n<li>Clients request exactly what they need</li>\n<li>Single request for complex data structures</li>\n<li>Reduced bandwidth usage</li>\n</ul>\n<h3>3. API Evolution</h3>\n<p><strong>REST:</strong></p>\n<pre><code class=\"language-python\"># Versioning required for breaking changes\r\n@app.get(\"/api/v1/users\")\r\nasync def get_users_v1():\r\n    pass\r\n\r\n@app.get(\"/api/v2/users\")\r\nasync def get_users_v2():\r\n    pass\n</code></pre>\n<p><strong>GraphQL:</strong></p>\n<pre><code class=\"language-python\"># Add new fields without breaking existing clients\r\n@strawberry.type\r\nclass User:\r\n    id: int\r\n    name: str\r\n    email: str\r\n    # New field added\r\n    phone: Optional[str] = None\n</code></pre>\n<h2>Performance Considerations</h2>\n<h3>REST Performance</h3>\n<p><strong>Advantages:</strong></p>\n<ul>\n<li>HTTP caching works well</li>\n<li>Simple to implement</li>\n<li>CDN-friendly</li>\n<li>Well-understood by developers</li>\n</ul>\n<p><strong>Disadvantages:</strong></p>\n<ul>\n<li>Multiple requests for complex data</li>\n<li>Over-fetching common</li>\n<li>N+1 query problems</li>\n</ul>\n<h3>GraphQL Performance</h3>\n<p><strong>Advantages:</strong></p>\n<ul>\n<li>Single request for complex data</li>\n<li>Reduced bandwidth</li>\n<li>Client controls data shape</li>\n<li>Real-time subscriptions</li>\n</ul>\n<p><strong>Disadvantages:</strong></p>\n<ul>\n<li>Complex caching strategies</li>\n<li>Potential for expensive queries</li>\n<li>Learning curve for developers</li>\n</ul>\n<h2>Caching Strategies</h2>\n<h3>REST Caching</h3>\n<pre><code class=\"language-python\">from fastapi import FastAPI, Request\r\nfrom fastapi.responses import Response\r\nimport redis\r\nimport json\r\n\r\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\r\n\r\n@app.get(\"/users/{user_id}\")\r\nasync def get_user(user_id: int):\r\n    cache_key = f\"user:{user_id}\"\r\n    cached = redis_client.get(cache_key)\r\n    \r\n    if cached:\r\n        return json.loads(cached)\r\n    \r\n    user = await fetch_user_from_db(user_id)\r\n    redis_client.setex(cache_key, 300, json.dumps(user.dict()))\r\n    return user\n</code></pre>\n<h3>GraphQL Caching</h3>\n<pre><code class=\"language-python\">import strawberry\r\nfrom strawberry.extensions import QueryDepthLimiter, QueryComplexityLimiter\r\n\r\n# Add query complexity analysis\r\n@strawberry.type\r\nclass Query:\r\n    @strawberry.field\r\n    def users(self) -> List[User]:\r\n        # Implement field-level caching\r\n        pass\r\n\r\n# Configure extensions\r\nschema = strawberry.Schema(\r\n    query=Query,\r\n    extensions=[\r\n        QueryDepthLimiter(max_depth=10),\r\n        QueryComplexityLimiter(max_complexity=1000)\r\n    ]\r\n)\n</code></pre>\n<h2>Error Handling</h2>\n<h3>REST Error Handling</h3>\n<pre><code class=\"language-python\">from fastapi import HTTPException\r\n\r\n@app.get(\"/users/{user_id}\")\r\nasync def get_user(user_id: int):\r\n    user = await fetch_user_from_db(user_id)\r\n    if not user:\r\n        raise HTTPException(status_code=404, detail=\"User not found\")\r\n    return user\n</code></pre>\n<h3>GraphQL Error Handling</h3>\n<pre><code class=\"language-python\">import strawberry\r\nfrom strawberry.types import Info\r\n\r\n@strawberry.type\r\nclass UserNotFound:\r\n    message: str = \"User not found\"\r\n\r\n@strawberry.type\r\nclass User:\r\n    id: int\r\n    name: str\r\n\r\n@strawberry.type\r\nclass Query:\r\n    @strawberry.field\r\n    def user(self, user_id: int) -> strawberry.union(\"UserResult\", User, UserNotFound):\r\n        user = fetch_user_from_db(user_id)\r\n        if not user:\r\n            return UserNotFound()\r\n        return user\n</code></pre>\n<h2>When to Choose REST</h2>\n<p><strong>Choose REST when:</strong></p>\n<ul>\n<li>Building simple CRUD applications</li>\n<li>Need HTTP caching</li>\n<li>Working with mobile apps (better caching support)</li>\n<li>Team is more familiar with REST</li>\n<li>Building public APIs</li>\n<li>Need simple integration with CDNs</li>\n</ul>\n<h2>When to Choose GraphQL</h2>\n<p><strong>Choose GraphQL when:</strong></p>\n<ul>\n<li>Building complex applications with varied data needs</li>\n<li>Need real-time subscriptions</li>\n<li>Want to reduce over-fetching</li>\n<li>Building internal APIs</li>\n<li>Need strong typing and introspection</li>\n<li>Working with modern frontend frameworks</li>\n</ul>\n<h2>Hybrid Approach</h2>\n<p>You can also use both approaches in the same application:</p>\n<pre><code class=\"language-python\">from fastapi import FastAPI\r\nfrom strawberry.fastapi import GraphQLRouter\r\n\r\napp = FastAPI()\r\n\r\n# REST endpoints for simple operations\r\n@app.get(\"/users/{user_id}\")\r\nasync def get_user_rest(user_id: int):\r\n    pass\r\n\r\n# GraphQL for complex queries\r\n@strawberry.type\r\nclass Query:\r\n    @strawberry.field\r\n    def user_with_posts_and_comments(self, user_id: int):\r\n        pass\r\n\r\nschema = strawberry.Schema(query=Query)\r\ngraphql_app = GraphQLRouter(schema)\r\napp.include_router(graphql_app, prefix=\"/graphql\")\n</code></pre>\n<h2>Conclusion</h2>\n<p>Both REST and GraphQL have their place in modern Python backend development:</p>\n<ul>\n<li><strong>REST</strong> is simpler, more widely understood, and works well for straightforward APIs</li>\n<li><strong>GraphQL</strong> provides more flexibility and efficiency for complex applications</li>\n</ul>\n<p>The choice depends on your specific requirements, team expertise, and application complexity. Consider starting with REST for simplicity and migrating to GraphQL as your needs grow more complex.</p>\n<p>Remember that the best API is one that serves your users' needs effectively while being maintainable and performant for your development team.</p>\n"
  },
  {
    "id": 2,
    "title": "Optimizing FastAPI Performance for High-Traffic Applications",
    "excerpt": "Learn advanced techniques for optimizing FastAPI applications to handle high traffic loads, including async/await patterns, database optimizations, and caching strategies.",
    "date": "March 15, 2023",
    "readTime": "10 min read",
    "image": null,
    "slug": "optimizing-fastapi-performance",
    "tags": [
      "FastAPI",
      "Python",
      "Performance",
      "Backend"
    ],
    "content": "<h1>Optimizing FastAPI Performance for High-Traffic Applications</h1>\n<p>FastAPI has become one of the most popular Python web frameworks for building high-performance APIs. However, as your application scales and handles more traffic, you'll need to implement specific optimization techniques to maintain excellent performance.</p>\n<h2>Understanding FastAPI's Performance Characteristics</h2>\n<p>FastAPI is built on top of Starlette and Pydantic, which provides several performance advantages:</p>\n<ul>\n<li><strong>Automatic async/await support</strong>: Built-in support for Python's async/await syntax</li>\n<li><strong>Type validation with Pydantic</strong>: Fast request/response validation</li>\n<li><strong>Automatic OpenAPI documentation</strong>: No performance overhead for documentation generation</li>\n<li><strong>Dependency injection system</strong>: Efficient dependency management</li>\n</ul>\n<h2>Database Optimization Strategies</h2>\n<h3>1. Connection Pooling</h3>\n<pre><code class=\"language-python\">from sqlalchemy import create_engine\r\nfrom sqlalchemy.pool import QueuePool\r\n\r\nengine = create_engine(\r\n    \"postgresql://user:password@localhost/db\",\r\n    poolclass=QueuePool,\r\n    pool_size=20,\r\n    max_overflow=30,\r\n    pool_pre_ping=True\r\n)\n</code></pre>\n<h3>2. Query Optimization</h3>\n<pre><code class=\"language-python\">from sqlalchemy.orm import selectinload, joinedload\r\n\r\n# Use selectinload for one-to-many relationships\r\nusers = await session.execute(\r\n    select(User).options(selectinload(User.posts))\r\n)\r\n\r\n# Use joinedload for many-to-one relationships\r\nposts = await session.execute(\r\n    select(Post).options(joinedload(Post.author))\r\n)\n</code></pre>\n<h2>Caching Implementation</h2>\n<h3>Redis Caching</h3>\n<pre><code class=\"language-python\">import redis\r\nimport json\r\nfrom functools import wraps\r\n\r\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\r\n\r\ndef cache_result(expiration: int = 300):\r\n    def decorator(func):\r\n        @wraps(func)\r\n        async def wrapper(*args, **kwargs):\r\n            cache_key = f\"{func.__name__}:{hash(str(args) + str(kwargs))}\"\r\n            cached = redis_client.get(cache_key)\r\n            \r\n            if cached:\r\n                return json.loads(cached)\r\n            \r\n            result = await func(*args, **kwargs)\r\n            redis_client.setex(cache_key, expiration, json.dumps(result))\r\n            return result\r\n        return wrapper\r\n    return decorator\n</code></pre>\n<h2>Async Best Practices</h2>\n<h3>1. Proper Async Function Usage</h3>\n<pre><code class=\"language-python\"># Good: Use async for I/O operations\r\nasync def get_user_data(user_id: int):\r\n    async with get_db_session() as session:\r\n        result = await session.execute(select(User).where(User.id == user_id))\r\n        return result.scalar_one_or_none()\r\n\r\n# Avoid: Don't use async for CPU-bound operations\r\nasync def calculate_fibonacci(n: int):  # This is wrong\r\n    if n &#x3C;= 1:\r\n        return n\r\n    return await calculate_fibonacci(n-1) + await calculate_fibonacci(n-2)\n</code></pre>\n<h3>2. Background Tasks</h3>\n<pre><code class=\"language-python\">from fastapi import BackgroundTasks\r\n\r\n@app.post(\"/send-email\")\r\nasync def send_email(\r\n    email: EmailSchema,\r\n    background_tasks: BackgroundTasks\r\n):\r\n    background_tasks.add_task(send_email_task, email)\r\n    return {\"message\": \"Email will be sent in the background\"}\n</code></pre>\n<h2>Monitoring and Profiling</h2>\n<h3>1. Request Timing Middleware</h3>\n<pre><code class=\"language-python\">import time\r\nfrom fastapi import Request\r\n\r\n@app.middleware(\"http\")\r\nasync def add_process_time_header(request: Request, call_next):\r\n    start_time = time.time()\r\n    response = await call_next(request)\r\n    process_time = time.time() - start_time\r\n    response.headers[\"X-Process-Time\"] = str(process_time)\r\n    return response\n</code></pre>\n<h3>2. Database Query Monitoring</h3>\n<pre><code class=\"language-python\">from sqlalchemy import event\r\nfrom sqlalchemy.engine import Engine\r\nimport logging\r\n\r\nlogging.basicConfig()\r\nlogger = logging.getLogger(\"sqlalchemy.engine\")\r\nlogger.setLevel(logging.INFO)\r\n\r\n@event.listens_for(Engine, \"before_cursor_execute\")\r\ndef receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\r\n    context._query_start_time = time.time()\r\n\r\n@event.listens_for(Engine, \"after_cursor_execute\")\r\ndef receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):\r\n    total = time.time() - context._query_start_time\r\n    logger.info(\"Total time: %f\", total)\n</code></pre>\n<h2>Conclusion</h2>\n<p>Optimizing FastAPI performance requires a multi-faceted approach:</p>\n<ol>\n<li><strong>Database optimization</strong>: Proper connection pooling and query optimization</li>\n<li><strong>Caching strategies</strong>: Implement Redis or in-memory caching</li>\n<li><strong>Async best practices</strong>: Use async/await correctly for I/O operations</li>\n<li><strong>Background tasks</strong>: Offload heavy operations</li>\n<li><strong>Monitoring</strong>: Track performance metrics and identify bottlenecks</li>\n</ol>\n<p>By implementing these techniques, you can build FastAPI applications that handle high traffic loads while maintaining excellent response times and user experience.</p>\n"
  },
  {
    "id": 3,
    "title": "Building Scalable Python Microservices with FastAPI and RabbitMQ",
    "excerpt": "A comprehensive guide to designing and implementing a scalable microservices architecture using Python, FastAPI, and message queues for reliable communication.",
    "date": "February 8, 2023",
    "readTime": "12 min read",
    "image": null,
    "slug": "scalable-python-microservices",
    "tags": [
      "Microservices",
      "Python",
      "FastAPI",
      "RabbitMQ"
    ],
    "content": "<h1>Building Scalable Python Microservices with FastAPI and RabbitMQ</h1>\n<p>Microservices architecture has become the go-to approach for building large-scale, maintainable applications. This guide will walk you through creating a robust microservices system using Python, FastAPI, and RabbitMQ.</p>\n<h2>Understanding Microservices Architecture</h2>\n<p>Microservices are small, independent services that communicate over well-defined APIs. Each service is responsible for a specific business capability and can be developed, deployed, and scaled independently.</p>\n<h3>Key Benefits</h3>\n<ul>\n<li><strong>Scalability</strong>: Scale individual services based on demand</li>\n<li><strong>Technology diversity</strong>: Use different technologies for different services</li>\n<li><strong>Fault isolation</strong>: Failure in one service doesn't bring down the entire system</li>\n<li><strong>Team autonomy</strong>: Different teams can work on different services</li>\n</ul>\n<h2>Service Communication Patterns</h2>\n<h3>1. Synchronous Communication (HTTP/REST)</h3>\n<pre><code class=\"language-python\"># Service A calling Service B\r\nimport httpx\r\n\r\nasync def get_user_orders(user_id: int):\r\n    async with httpx.AsyncClient() as client:\r\n        response = await client.get(f\"http://user-service:8000/users/{user_id}\")\r\n        user = response.json()\r\n        \r\n        response = await client.get(f\"http://order-service:8000/orders?user_id={user_id}\")\r\n        orders = response.json()\r\n        \r\n        return {\"user\": user, \"orders\": orders}\n</code></pre>\n<h3>2. Asynchronous Communication (Message Queues)</h3>\n<pre><code class=\"language-python\"># Publisher\r\nimport pika\r\nimport json\r\n\r\ndef publish_order_created(order_data):\r\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\r\n    channel = connection.channel()\r\n    \r\n    channel.queue_declare(queue='order_created')\r\n    channel.basic_publish(\r\n        exchange='',\r\n        routing_key='order_created',\r\n        body=json.dumps(order_data)\r\n    )\r\n    connection.close()\r\n\r\n# Consumer\r\ndef consume_order_created():\r\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\r\n    channel = connection.channel()\r\n    \r\n    channel.queue_declare(queue='order_created')\r\n    \r\n    def callback(ch, method, properties, body):\r\n        order_data = json.loads(body)\r\n        # Process the order\r\n        print(f\"Processing order: {order_data}\")\r\n    \r\n    channel.basic_consume(queue='order_created', on_message_callback=callback)\r\n    channel.start_consuming()\n</code></pre>\n<h2>Service Discovery and Load Balancing</h2>\n<h3>Using Consul for Service Discovery</h3>\n<pre><code class=\"language-python\">import consul\r\nimport random\r\n\r\nclass ServiceDiscovery:\r\n    def __init__(self):\r\n        self.consul = consul.Consul()\r\n    \r\n    def register_service(self, service_name, service_id, address, port):\r\n        self.consul.agent.service.register(\r\n            name=service_name,\r\n            service_id=service_id,\r\n            address=address,\r\n            port=port,\r\n            check=consul.Check.http(f\"http://{address}:{port}/health\", \"10s\")\r\n        )\r\n    \r\n    def discover_service(self, service_name):\r\n        services = self.consul.health.service(service_name)[1]\r\n        if services:\r\n            service = random.choice(services)\r\n            return f\"http://{service['Service']['Address']}:{service['Service']['Port']}\"\r\n        return None\n</code></pre>\n<h2>Database per Service Pattern</h2>\n<h3>User Service Database</h3>\n<pre><code class=\"language-python\"># user_service/models.py\r\nfrom sqlalchemy import Column, Integer, String, DateTime\r\nfrom sqlalchemy.ext.declarative import declarative_base\r\n\r\nBase = declarative_base()\r\n\r\nclass User(Base):\r\n    __tablename__ = \"users\"\r\n    \r\n    id = Column(Integer, primary_key=True)\r\n    email = Column(String, unique=True, index=True)\r\n    name = Column(String)\r\n    created_at = Column(DateTime)\n</code></pre>\n<h3>Order Service Database</h3>\n<pre><code class=\"language-python\"># order_service/models.py\r\nfrom sqlalchemy import Column, Integer, String, DateTime, ForeignKey\r\nfrom sqlalchemy.ext.declarative import declarative_base\r\n\r\nBase = declarative_base()\r\n\r\nclass Order(Base):\r\n    __tablename__ = \"orders\"\r\n    \r\n    id = Column(Integer, primary_key=True)\r\n    user_id = Column(Integer)  # Reference to user in another service\r\n    product_name = Column(String)\r\n    amount = Column(Integer)\r\n    created_at = Column(DateTime)\n</code></pre>\n<h2>API Gateway Implementation</h2>\n<pre><code class=\"language-python\">from fastapi import FastAPI, HTTPException\r\nfrom fastapi.middleware.cors import CORSMiddleware\r\nimport httpx\r\n\r\napp = FastAPI()\r\n\r\napp.add_middleware(\r\n    CORSMiddleware,\r\n    allow_origins=[\"*\"],\r\n    allow_credentials=True,\r\n    allow_methods=[\"*\"],\r\n    allow_headers=[\"*\"],\r\n)\r\n\r\nclass APIGateway:\r\n    def __init__(self):\r\n        self.services = {\r\n            \"user\": \"http://user-service:8000\",\r\n            \"order\": \"http://order-service:8000\",\r\n            \"payment\": \"http://payment-service:8000\"\r\n        }\r\n    \r\n    async def forward_request(self, service_name: str, path: str, method: str, data: dict = None):\r\n        service_url = self.services.get(service_name)\r\n        if not service_url:\r\n            raise HTTPException(status_code=404, detail=\"Service not found\")\r\n        \r\n        async with httpx.AsyncClient() as client:\r\n            response = await client.request(\r\n                method=method,\r\n                url=f\"{service_url}{path}\",\r\n                json=data\r\n            )\r\n            return response.json()\r\n\r\ngateway = APIGateway()\r\n\r\n@app.get(\"/users/{user_id}\")\r\nasync def get_user(user_id: int):\r\n    return await gateway.forward_request(\"user\", f\"/users/{user_id}\", \"GET\")\r\n\r\n@app.post(\"/orders\")\r\nasync def create_order(order_data: dict):\r\n    return await gateway.forward_request(\"order\", \"/orders\", \"POST\", order_data)\n</code></pre>\n<h2>Monitoring and Observability</h2>\n<h3>Distributed Tracing with OpenTelemetry</h3>\n<pre><code class=\"language-python\">from opentelemetry import trace\r\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\r\nfrom opentelemetry.sdk.trace import TracerProvider\r\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\r\n\r\n# Configure tracing\r\ntrace.set_tracer_provider(TracerProvider())\r\ntracer = trace.get_tracer(__name__)\r\n\r\njaeger_exporter = JaegerExporter(\r\n    agent_host_name=\"localhost\",\r\n    agent_port=14268,\r\n)\r\n\r\nspan_processor = BatchSpanProcessor(jaeger_exporter)\r\ntrace.get_tracer_provider().add_span_processor(span_processor)\r\n\r\n# Use in your services\r\n@app.get(\"/users/{user_id}\")\r\nasync def get_user(user_id: int):\r\n    with tracer.start_as_current_span(\"get_user\") as span:\r\n        span.set_attribute(\"user.id\", user_id)\r\n        # Your service logic here\r\n        return {\"user_id\": user_id}\n</code></pre>\n<h2>Deployment with Docker</h2>\n<h3>Dockerfile for Python Services</h3>\n<pre><code class=\"language-dockerfile\">FROM python:3.11-slim\r\n\r\nWORKDIR /app\r\n\r\nCOPY requirements.txt .\r\nRUN pip install --no-cache-dir -r requirements.txt\r\n\r\nCOPY . .\r\n\r\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>\n<h3>Docker Compose for Local Development</h3>\n<pre><code class=\"language-yaml\">version: '3.8'\r\n\r\nservices:\r\n  user-service:\r\n    build: ./user-service\r\n    ports:\r\n      - \"8001:8000\"\r\n    environment:\r\n      - DATABASE_URL=postgresql://user:password@db:5432/user_db\r\n    depends_on:\r\n      - db\r\n      - rabbitmq\r\n\r\n  order-service:\r\n    build: ./order-service\r\n    ports:\r\n      - \"8002:8000\"\r\n    environment:\r\n      - DATABASE_URL=postgresql://user:password@db:5432/order_db\r\n    depends_on:\r\n      - db\r\n      - rabbitmq\r\n\r\n  api-gateway:\r\n    build: ./api-gateway\r\n    ports:\r\n      - \"8000:8000\"\r\n    depends_on:\r\n      - user-service\r\n      - order-service\r\n\r\n  rabbitmq:\r\n    image: rabbitmq:3-management\r\n    ports:\r\n      - \"5672:5672\"\r\n      - \"15672:15672\"\r\n\r\n  db:\r\n    image: postgres:13\r\n    environment:\r\n      - POSTGRES_PASSWORD=password\r\n    volumes:\r\n      - postgres_data:/var/lib/postgresql/data\r\n\r\nvolumes:\r\n  postgres_data:\n</code></pre>\n<h2>Best Practices</h2>\n<ol>\n<li><strong>Service Boundaries</strong>: Define clear service boundaries based on business capabilities</li>\n<li><strong>Data Consistency</strong>: Use eventual consistency and saga patterns for distributed transactions</li>\n<li><strong>Error Handling</strong>: Implement circuit breakers and retry mechanisms</li>\n<li><strong>Security</strong>: Use API keys, JWT tokens, and proper authentication</li>\n<li><strong>Testing</strong>: Write comprehensive tests for each service and integration tests</li>\n<li><strong>Documentation</strong>: Maintain clear API documentation for each service</li>\n</ol>\n<h2>Conclusion</h2>\n<p>Building scalable microservices with Python and FastAPI requires careful planning and implementation. By following the patterns and practices outlined in this guide, you can create a robust, maintainable microservices architecture that can scale with your business needs.</p>\n<p>Remember to start simple and gradually add complexity as your system grows. Monitor your services closely and be prepared to refactor as you learn more about your domain and requirements.</p>\n"
  }
]

// Get featured blog posts (top 3)
export const featuredBlogPosts = allBlogPosts.slice(0, 3)

export default {
  allBlogPosts,
  featuredBlogPosts,
}
