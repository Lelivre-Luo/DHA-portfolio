// This file is auto-generated. Do not edit manually.
// Run 'pnpm run build:content' to regenerate.

export type BlogPost = {
  id: number
  title: string
  excerpt: string
  date: string
  readTime: string
  slug: string
  tags: string[]
  image?: string | null
  content?: string
}

export const allBlogPosts: BlogPost[] = [
  {
    "id": 1,
    "title": "[待替换] GraphQL vs REST in Python Backend Applications",
    "excerpt": "[待替换] An in-depth comparison of GraphQL and REST API approaches in Python backend applications, with real-world examples and performance considerations.",
    "date": "[待替换] January 22, 2023",
    "readTime": "[待替换] 8 min read",
    "image": "[待替换] null",
    "slug": "graphql-vs-rest-python",
    "tags": [
      "[待替换] GraphQL",
      "[待替换] REST API",
      "[待替换] Python",
      "[待替换] Backend"
    ],
    "content": "<h1>[待替换] GraphQL vs REST in Python Backend Applications</h1>\n<p>[待替换] When building modern web applications, choosing the right API architecture is crucial for performance, maintainability, and developer experience. In this comprehensive guide, we'll explore the differences between GraphQL and REST APIs in Python backend applications.</p>\n<h2>[待替换] Understanding REST APIs</h2>\n<h3>[待替换] What is REST?</h3>\n<p>[待替换] REST (Representational State Transfer) is an architectural style that uses HTTP methods to perform operations on resources. It's based on a stateless, client-server communication protocol.</p>\n<h3>[待替换] REST Characteristics</h3>\n<ul>\n<li>[待替换] <strong>Stateless</strong>: Each request contains all necessary information</li>\n<li>[待替换] <strong>Resource-based</strong>: URLs represent resources</li>\n<li>[待替换] <strong>HTTP Methods</strong>: GET, POST, PUT, DELETE for operations</li>\n<li>[待替换] <strong>JSON/XML</strong>: Common data exchange formats</li>\n</ul>\n<h3>[待替换] REST Example in Python</h3>\n<pre><code class=\"language-python\"># Flask REST API example\nfrom flask import Flask, jsonify, request\n\napp = Flask(__name__)\n\n@app.route('/api/users', methods=['GET'])\ndef get_users():\n    users = User.query.all()\n    return jsonify([user.to_dict() for user in users])\n\n@app.route('/api/users/&#x3C;int:user_id>', methods=['GET'])\ndef get_user(user_id):\n    user = User.query.get_or_404(user_id)\n    return jsonify(user.to_dict())\n\n@app.route('/api/users', methods=['POST'])\ndef create_user():\n    data = request.get_json()\n    user = User(**data)\n    db.session.add(user)\n    db.session.commit()\n    return jsonify(user.to_dict()), 201\n</code></pre>\n<h2>[待替换] Understanding GraphQL</h2>\n<h3>[待替换] What is GraphQL?</h3>\n<p>[待替换] GraphQL is a query language and runtime for APIs that allows clients to request exactly the data they need. It provides a single endpoint for all operations.</p>\n<h3>[待替换] GraphQL Characteristics</h3>\n<ul>\n<li>[待替换] <strong>Single Endpoint</strong>: One endpoint for all operations</li>\n<li>[待替换] <strong>Client-specified Queries</strong>: Clients define what data they need</li>\n<li>[待替换] <strong>Strong Typing</strong>: Schema defines data structure</li>\n<li>[待替换] <strong>Real-time</strong>: Subscriptions for live updates</li>\n</ul>\n<h3>[待替换] GraphQL Example in Python</h3>\n<pre><code class=\"language-python\"># Graphene GraphQL example\nimport graphene\nfrom graphene_sqlalchemy import SQLAlchemyObjectType\n\nclass UserType(SQLAlchemyObjectType):\n    class Meta:\n        model = User\n        interfaces = (graphene.relay.Node, )\n\nclass Query(graphene.ObjectType):\n    users = graphene.List(UserType)\n    user = graphene.Field(UserType, id=graphene.Int())\n\n    def resolve_users(self, info):\n        return User.query.all()\n\n    def resolve_user(self, info, id):\n        return User.query.get(id)\n\nschema = graphene.Schema(query=Query)\n</code></pre>\n<h2>[待替换] Detailed Comparison</h2>\n<h3>[待替换] Data Fetching</h3>\n<h4>[待替换] REST Approach</h4>\n<pre><code class=\"language-python\"># Multiple requests needed\nGET /api/users/1\nGET /api/users/1/posts\nGET /api/users/1/posts/1/comments\n</code></pre>\n<h4>[待替换] GraphQL Approach</h4>\n<pre><code class=\"language-graphql\"># Single request\nquery {\n  user(id: 1) {\n    name\n    email\n    posts {\n      title\n      content\n      comments {\n        text\n        author\n      }\n    }\n  }\n}\n</code></pre>\n<h3>[待替换] Over-fetching and Under-fetching</h3>\n<h4>[待替换] REST Issues</h4>\n<ul>\n<li>[待替换] <strong>Over-fetching</strong>: Getting more data than needed</li>\n<li>[待替换] <strong>Under-fetching</strong>: Not getting enough data in one request</li>\n<li>[待替换] <strong>Multiple Requests</strong>: Need several API calls for complex data</li>\n</ul>\n<h4>[待替换] GraphQL Solutions</h4>\n<ul>\n<li>[待替换] <strong>Precise Data</strong>: Request exactly what you need</li>\n<li>[待替换] <strong>Single Request</strong>: Get all related data in one query</li>\n<li>[待替换] <strong>Efficient</strong>: Reduce bandwidth and improve performance</li>\n</ul>\n<h2>[待替换] Performance Considerations</h2>\n<h3>[待替换] Network Efficiency</h3>\n<h4>[待替换] REST Performance</h4>\n<pre><code class=\"language-python\"># REST: Multiple requests\n# Request 1: GET /api/users/1 (200ms)\n# Request 2: GET /api/users/1/posts (150ms)\n# Request 3: GET /api/users/1/posts/1/comments (100ms)\n# Total: 450ms\n</code></pre>\n<h4>[待替换] GraphQL Performance</h4>\n<pre><code class=\"language-python\"># GraphQL: Single request\n# Request: POST /graphql (300ms)\n# Total: 300ms\n</code></pre>\n<h3>[待替换] Caching Strategies</h3>\n<h4>[待替换] REST Caching</h4>\n<ul>\n<li>[待替换] <strong>HTTP Caching</strong>: Leverage HTTP cache headers</li>\n<li>[待替换] <strong>CDN Caching</strong>: Cache at edge locations</li>\n<li>[待替换] <strong>Browser Caching</strong>: Client-side caching</li>\n<li>[待替换] <strong>Simple</strong>: Easy to implement and understand</li>\n</ul>\n<h4>[待替换] GraphQL Caching</h4>\n<ul>\n<li>[待替换] <strong>Query Caching</strong>: Cache based on query structure</li>\n<li>[待替换] <strong>Field Caching</strong>: Cache individual fields</li>\n<li>[待替换] <strong>Complex</strong>: Requires specialized caching solutions</li>\n<li>[待替换] <strong>Advanced</strong>: More sophisticated caching strategies</li>\n</ul>\n<h2>[待替换] Development Experience</h2>\n<h3>[待替换] API Documentation</h3>\n<h4>[待替换] REST Documentation</h4>\n<pre><code class=\"language-python\"># Swagger/OpenAPI documentation\nfrom flask_restx import Api, Resource, fields\n\napi = Api(app, doc='/docs/')\n\nuser_model = api.model('User', {\n    'id': fields.Integer(required=True),\n    'name': fields.String(required=True),\n    'email': fields.String(required=True)\n})\n\n@api.route('/users')\nclass UserList(Resource):\n    @api.marshal_list_with(user_model)\n    def get(self):\n        return User.query.all()\n</code></pre>\n<h4>[待替换] GraphQL Documentation</h4>\n<pre><code class=\"language-python\"># GraphQL schema introspection\nclass UserType(SQLAlchemyObjectType):\n    class Meta:\n        model = User\n        fields = (\"id\", \"name\", \"email\", \"posts\")\n\n# Automatic documentation generation\n# Schema introspection provides self-documenting API\n</code></pre>\n<h3>[待替换] Type Safety</h3>\n<h4>[待替换] REST Type Safety</h4>\n<ul>\n<li>[待替换] <strong>Runtime Validation</strong>: Validate data at runtime</li>\n<li>[待替换] <strong>Manual Validation</strong>: Write validation logic manually</li>\n<li>[待替换] <strong>Error Handling</strong>: Handle validation errors</li>\n<li>[待替换] <strong>Flexible</strong>: Can handle various data formats</li>\n</ul>\n<h4>[待替换] GraphQL Type Safety</h4>\n<ul>\n<li>[待替换] <strong>Schema Validation</strong>: Compile-time type checking</li>\n<li>[待替换] <strong>Automatic Validation</strong>: Built-in validation</li>\n<li>[待替换] <strong>Type Generation</strong>: Generate types from schema</li>\n<li>[待替换] <strong>Strict</strong>: Enforces schema compliance</li>\n</ul>\n<h2>[待替换] Real-world Implementation</h2>\n<h3>[待替换] Python Libraries</h3>\n<h4>[待替换] REST Libraries</h4>\n<ul>\n<li>[待替换] <strong>Flask</strong>: Lightweight web framework</li>\n<li>[待替换] <strong>Django REST</strong>: Django's REST framework</li>\n<li>[待替换] <strong>FastAPI</strong>: Modern, fast web framework</li>\n<li>[待替换] <strong>Tornado</strong>: Asynchronous web framework</li>\n</ul>\n<h4>[待替换] GraphQL Libraries</h4>\n<ul>\n<li>[待替换] <strong>Graphene</strong>: GraphQL library for Python</li>\n<li>[待替换] <strong>Ariadne</strong>: Schema-first GraphQL library</li>\n<li>[待替换] <strong>Strawberry</strong>: Modern GraphQL library</li>\n<li>[待替换] <strong>Tartiflette</strong>: Async GraphQL engine</li>\n</ul>\n<h3>[待替换] FastAPI Example</h3>\n<h4>[待替换] REST with FastAPI</h4>\n<pre><code class=\"language-python\">from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass User(BaseModel):\n    id: int\n    name: str\n    email: str\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    return {\"id\": user_id, \"name\": \"John\", \"email\": \"john@example.com\"}\n\n@app.post(\"/users\")\nasync def create_user(user: User):\n    return user\n</code></pre>\n<h4>[待替换] GraphQL with Strawberry</h4>\n<pre><code class=\"language-python\">import strawberry\nfrom strawberry.fastapi import GraphQLRouter\n\n@strawberry.type\nclass User:\n    id: int\n    name: str\n    email: str\n\n@strawberry.type\nclass Query:\n    @strawberry.field\n    def user(self, id: int) -> User:\n        return User(id=id, name=\"John\", email=\"john@example.com\")\n\nschema = strawberry.Schema(query=Query)\ngraphql_app = GraphQLRouter(schema)\napp.include_router(graphql_app, prefix=\"/graphql\")\n</code></pre>\n<h2>[待替换] When to Choose REST</h2>\n<h3>[待替换] REST is Better When:</h3>\n<ul>\n<li>[待替换] <strong>Simple APIs</strong>: Straightforward CRUD operations</li>\n<li>[待替换] <strong>Caching Important</strong>: Heavy reliance on HTTP caching</li>\n<li>[待替换] <strong>Team Familiarity</strong>: Team is experienced with REST</li>\n<li>[待替换] <strong>Legacy Systems</strong>: Integrating with existing REST APIs</li>\n<li>[待替换] <strong>Mobile Apps</strong>: Better for mobile app development</li>\n<li>[待替换] <strong>Public APIs</strong>: Easier for third-party developers</li>\n</ul>\n<h3>[待替换] REST Advantages:</h3>\n<ul>\n<li>[待替换] <strong>Simplicity</strong>: Easy to understand and implement</li>\n<li>[待替换] <strong>Caching</strong>: Excellent HTTP caching support</li>\n<li>[待替换] <strong>Tools</strong>: Mature tooling and ecosystem</li>\n<li>[待替换] <strong>Standards</strong>: Well-established standards</li>\n<li>[待替换] <strong>Performance</strong>: Good performance for simple operations</li>\n</ul>\n<h2>[待替换] When to Choose GraphQL</h2>\n<h3>[待替换] GraphQL is Better When:</h3>\n<ul>\n<li>[待替换] <strong>Complex Data</strong>: Complex relationships and nested data</li>\n<li>[待替换] <strong>Mobile Apps</strong>: Need to minimize data transfer</li>\n<li>[待替换] <strong>Real-time</strong>: Need real-time updates</li>\n<li>[待替换] <strong>Multiple Clients</strong>: Different clients need different data</li>\n<li>[待替换] <strong>Rapid Development</strong>: Need to iterate quickly</li>\n<li>[待替换] <strong>Type Safety</strong>: Strong typing is important</li>\n</ul>\n<h3>[待替换] GraphQL Advantages:</h3>\n<ul>\n<li>[待替换] <strong>Efficiency</strong>: Fetch exactly what you need</li>\n<li>[待替换] <strong>Flexibility</strong>: Single endpoint for all operations</li>\n<li>[待替换] <strong>Type Safety</strong>: Strong typing and validation</li>\n<li>[待替换] <strong>Real-time</strong>: Built-in subscription support</li>\n<li>[待替换] <strong>Developer Experience</strong>: Better tooling and introspection</li>\n</ul>\n<h2>[待替换] Migration Strategies</h2>\n<h3>[待替换] REST to GraphQL Migration</h3>\n<ol>\n<li>[待替换] <strong>Gradual Migration</strong>: Implement GraphQL alongside REST</li>\n<li>[待替换] <strong>Schema Design</strong>: Design GraphQL schema based on REST endpoints</li>\n<li>[待替换] <strong>Resolver Implementation</strong>: Implement resolvers for existing data</li>\n<li>[待替换] <strong>Client Migration</strong>: Gradually migrate clients to GraphQL</li>\n<li>[待替换] <strong>Deprecation</strong>: Eventually deprecate REST endpoints</li>\n</ol>\n<h3>[待替换] Hybrid Approach</h3>\n<pre><code class=\"language-python\"># Support both REST and GraphQL\nfrom fastapi import FastAPI\nfrom strawberry.fastapi import GraphQLRouter\n\napp = FastAPI()\n\n# REST endpoints\n@app.get(\"/api/users/{user_id}\")\nasync def get_user_rest(user_id: int):\n    return {\"id\": user_id, \"name\": \"John\"}\n\n# GraphQL endpoint\n@strawberry.type\nclass Query:\n    @strawberry.field\n    def user(self, id: int) -> User:\n        return User(id=id, name=\"John\")\n\nschema = strawberry.Schema(query=Query)\ngraphql_app = GraphQLRouter(schema)\napp.include_router(graphql_app, prefix=\"/graphql\")\n</code></pre>\n<h2>[待替换] Best Practices</h2>\n<h3>[待替换] REST Best Practices</h3>\n<ul>\n<li>[待替换] <strong>Consistent URLs</strong>: Use consistent URL patterns</li>\n<li>[待替换] <strong>HTTP Status Codes</strong>: Use appropriate status codes</li>\n<li>[待替换] <strong>Error Handling</strong>: Implement proper error handling</li>\n<li>[待替换] <strong>Versioning</strong>: Use API versioning strategies</li>\n<li>[待替换] <strong>Documentation</strong>: Maintain comprehensive documentation</li>\n</ul>\n<h3>[待替换] GraphQL Best Practices</h3>\n<ul>\n<li>[待替换] <strong>Schema Design</strong>: Design clear and intuitive schemas</li>\n<li>[待替换] <strong>Resolver Efficiency</strong>: Optimize resolver performance</li>\n<li>[待替换] <strong>Error Handling</strong>: Implement proper error handling</li>\n<li>[待替换] <strong>Security</strong>: Implement proper security measures</li>\n<li>[待替换] <strong>Monitoring</strong>: Monitor query performance and usage</li>\n</ul>\n<h2>[待替换] Conclusion</h2>\n<p>[待替换] Both REST and GraphQL have their place in modern Python backend development. REST excels in simplicity, caching, and tooling maturity, while GraphQL provides efficiency, flexibility, and better developer experience for complex applications.</p>\n<p>[待替换] The choice between REST and GraphQL should be based on your specific requirements, team expertise, and project constraints. Consider factors like data complexity, client needs, performance requirements, and development timeline when making your decision.</p>\n<p>[待替换] Remember that you can also use both approaches in the same application, leveraging the strengths of each where they make the most sense.</p>\n<hr>\n<p><em>[待替换] Choose the right tool for the job, and your API will serve your users better.</em></p>\n"
  },
  {
    "id": 2,
    "title": "Optimizing FastAPI Performance for High-Traffic Applications",
    "excerpt": "Learn advanced techniques for optimizing FastAPI applications to handle high traffic loads, including async/await patterns, database optimizations, and caching strategies.",
    "date": "March 15, 2023",
    "readTime": "10 min read",
    "image": null,
    "slug": "optimizing-fastapi-performance",
    "tags": [
      "FastAPI",
      "Python",
      "Performance",
      "Backend"
    ],
    "content": "<h1>Optimizing FastAPI Performance for High-Traffic Applications</h1>\n<p>FastAPI has become one of the most popular Python web frameworks for building high-performance APIs. However, as your application scales and handles more traffic, you'll need to implement specific optimization techniques to maintain excellent performance.</p>\n<h2>Understanding FastAPI's Performance Characteristics</h2>\n<p>FastAPI is built on top of Starlette and Pydantic, which provides several performance advantages:</p>\n<ul>\n<li><strong>Automatic async/await support</strong>: Built-in support for Python's async/await syntax</li>\n<li><strong>Type validation with Pydantic</strong>: Fast request/response validation</li>\n<li><strong>Automatic OpenAPI documentation</strong>: No performance overhead for documentation generation</li>\n<li><strong>Dependency injection system</strong>: Efficient dependency management</li>\n</ul>\n<h2>Database Optimization Strategies</h2>\n<h3>1. Connection Pooling</h3>\n<pre><code class=\"language-python\">from sqlalchemy import create_engine\nfrom sqlalchemy.pool import QueuePool\n\nengine = create_engine(\n    \"postgresql://user:password@localhost/db\",\n    poolclass=QueuePool,\n    pool_size=20,\n    max_overflow=30,\n    pool_pre_ping=True\n)\n</code></pre>\n<h3>2. Query Optimization</h3>\n<pre><code class=\"language-python\">from sqlalchemy.orm import selectinload, joinedload\n\n# Use selectinload for one-to-many relationships\nusers = await session.execute(\n    select(User).options(selectinload(User.posts))\n)\n\n# Use joinedload for many-to-one relationships\nposts = await session.execute(\n    select(Post).options(joinedload(Post.author))\n)\n</code></pre>\n<h2>Caching Implementation</h2>\n<h3>Redis Caching</h3>\n<pre><code class=\"language-python\">import redis\nimport json\nfrom functools import wraps\n\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\n\ndef cache_result(expiration: int = 300):\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            cache_key = f\"{func.__name__}:{hash(str(args) + str(kwargs))}\"\n            cached = redis_client.get(cache_key)\n            \n            if cached:\n                return json.loads(cached)\n            \n            result = await func(*args, **kwargs)\n            redis_client.setex(cache_key, expiration, json.dumps(result))\n            return result\n        return wrapper\n    return decorator\n</code></pre>\n<h2>Async Best Practices</h2>\n<h3>1. Proper Async Function Usage</h3>\n<pre><code class=\"language-python\"># Good: Use async for I/O operations\nasync def get_user_data(user_id: int):\n    async with get_db_session() as session:\n        result = await session.execute(select(User).where(User.id == user_id))\n        return result.scalar_one_or_none()\n\n# Avoid: Don't use async for CPU-bound operations\nasync def calculate_fibonacci(n: int):  # This is wrong\n    if n &#x3C;= 1:\n        return n\n    return await calculate_fibonacci(n-1) + await calculate_fibonacci(n-2)\n</code></pre>\n<h3>2. Background Tasks</h3>\n<pre><code class=\"language-python\">from fastapi import BackgroundTasks\n\n@app.post(\"/send-email\")\nasync def send_email(\n    email: EmailSchema,\n    background_tasks: BackgroundTasks\n):\n    background_tasks.add_task(send_email_task, email)\n    return {\"message\": \"Email will be sent in the background\"}\n</code></pre>\n<h2>Monitoring and Profiling</h2>\n<h3>1. Request Timing Middleware</h3>\n<pre><code class=\"language-python\">import time\nfrom fastapi import Request\n\n@app.middleware(\"http\")\nasync def add_process_time_header(request: Request, call_next):\n    start_time = time.time()\n    response = await call_next(request)\n    process_time = time.time() - start_time\n    response.headers[\"X-Process-Time\"] = str(process_time)\n    return response\n</code></pre>\n<h3>2. Database Query Monitoring</h3>\n<pre><code class=\"language-python\">from sqlalchemy import event\nfrom sqlalchemy.engine import Engine\nimport logging\n\nlogging.basicConfig()\nlogger = logging.getLogger(\"sqlalchemy.engine\")\nlogger.setLevel(logging.INFO)\n\n@event.listens_for(Engine, \"before_cursor_execute\")\ndef receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n    context._query_start_time = time.time()\n\n@event.listens_for(Engine, \"after_cursor_execute\")\ndef receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n    total = time.time() - context._query_start_time\n    logger.info(\"Total time: %f\", total)\n</code></pre>\n<h2>Conclusion</h2>\n<p>Optimizing FastAPI performance requires a multi-faceted approach:</p>\n<ol>\n<li><strong>Database optimization</strong>: Proper connection pooling and query optimization</li>\n<li><strong>Caching strategies</strong>: Implement Redis or in-memory caching</li>\n<li><strong>Async best practices</strong>: Use async/await correctly for I/O operations</li>\n<li><strong>Background tasks</strong>: Offload heavy operations</li>\n<li><strong>Monitoring</strong>: Track performance metrics and identify bottlenecks</li>\n</ol>\n<p>By implementing these techniques, you can build FastAPI applications that handle high traffic loads while maintaining excellent response times and user experience.</p>\n"
  },
  {
    "id": 3,
    "title": "Building Scalable Python Microservices with FastAPI and RabbitMQ",
    "excerpt": "A comprehensive guide to designing and implementing a scalable microservices architecture using Python, FastAPI, and message queues for reliable communication.",
    "date": "February 8, 2023",
    "readTime": "12 min read",
    "image": null,
    "slug": "scalable-python-microservices",
    "tags": [
      "Microservices",
      "Python",
      "FastAPI",
      "RabbitMQ"
    ],
    "content": "<h1>Building Scalable Python Microservices with FastAPI and RabbitMQ</h1>\n<p>Microservices architecture has become the go-to approach for building large-scale, maintainable applications. This guide will walk you through creating a robust microservices system using Python, FastAPI, and RabbitMQ.</p>\n<h2>Understanding Microservices Architecture</h2>\n<p>Microservices are small, independent services that communicate over well-defined APIs. Each service is responsible for a specific business capability and can be developed, deployed, and scaled independently.</p>\n<h3>Key Benefits</h3>\n<ul>\n<li><strong>Scalability</strong>: Scale individual services based on demand</li>\n<li><strong>Technology diversity</strong>: Use different technologies for different services</li>\n<li><strong>Fault isolation</strong>: Failure in one service doesn't bring down the entire system</li>\n<li><strong>Team autonomy</strong>: Different teams can work on different services</li>\n</ul>\n<h2>Service Communication Patterns</h2>\n<h3>1. Synchronous Communication (HTTP/REST)</h3>\n<pre><code class=\"language-python\"># Service A calling Service B\nimport httpx\n\nasync def get_user_orders(user_id: int):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"http://user-service:8000/users/{user_id}\")\n        user = response.json()\n        \n        response = await client.get(f\"http://order-service:8000/orders?user_id={user_id}\")\n        orders = response.json()\n        \n        return {\"user\": user, \"orders\": orders}\n</code></pre>\n<h3>2. Asynchronous Communication (Message Queues)</h3>\n<pre><code class=\"language-python\"># Publisher\nimport pika\nimport json\n\ndef publish_order_created(order_data):\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n    channel = connection.channel()\n    \n    channel.queue_declare(queue='order_created')\n    channel.basic_publish(\n        exchange='',\n        routing_key='order_created',\n        body=json.dumps(order_data)\n    )\n    connection.close()\n\n# Consumer\ndef consume_order_created():\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n    channel = connection.channel()\n    \n    channel.queue_declare(queue='order_created')\n    \n    def callback(ch, method, properties, body):\n        order_data = json.loads(body)\n        # Process the order\n        print(f\"Processing order: {order_data}\")\n    \n    channel.basic_consume(queue='order_created', on_message_callback=callback)\n    channel.start_consuming()\n</code></pre>\n<h2>Service Discovery and Load Balancing</h2>\n<h3>Using Consul for Service Discovery</h3>\n<pre><code class=\"language-python\">import consul\nimport random\n\nclass ServiceDiscovery:\n    def __init__(self):\n        self.consul = consul.Consul()\n    \n    def register_service(self, service_name, service_id, address, port):\n        self.consul.agent.service.register(\n            name=service_name,\n            service_id=service_id,\n            address=address,\n            port=port,\n            check=consul.Check.http(f\"http://{address}:{port}/health\", \"10s\")\n        )\n    \n    def discover_service(self, service_name):\n        services = self.consul.health.service(service_name)[1]\n        if services:\n            service = random.choice(services)\n            return f\"http://{service['Service']['Address']}:{service['Service']['Port']}\"\n        return None\n</code></pre>\n<h2>Database per Service Pattern</h2>\n<h3>User Service Database</h3>\n<pre><code class=\"language-python\"># user_service/models.py\nfrom sqlalchemy import Column, Integer, String, DateTime\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = \"users\"\n    \n    id = Column(Integer, primary_key=True)\n    email = Column(String, unique=True, index=True)\n    name = Column(String)\n    created_at = Column(DateTime)\n</code></pre>\n<h3>Order Service Database</h3>\n<pre><code class=\"language-python\"># order_service/models.py\nfrom sqlalchemy import Column, Integer, String, DateTime, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass Order(Base):\n    __tablename__ = \"orders\"\n    \n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer)  # Reference to user in another service\n    product_name = Column(String)\n    amount = Column(Integer)\n    created_at = Column(DateTime)\n</code></pre>\n<h2>API Gateway Implementation</h2>\n<pre><code class=\"language-python\">from fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport httpx\n\napp = FastAPI()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\nclass APIGateway:\n    def __init__(self):\n        self.services = {\n            \"user\": \"http://user-service:8000\",\n            \"order\": \"http://order-service:8000\",\n            \"payment\": \"http://payment-service:8000\"\n        }\n    \n    async def forward_request(self, service_name: str, path: str, method: str, data: dict = None):\n        service_url = self.services.get(service_name)\n        if not service_url:\n            raise HTTPException(status_code=404, detail=\"Service not found\")\n        \n        async with httpx.AsyncClient() as client:\n            response = await client.request(\n                method=method,\n                url=f\"{service_url}{path}\",\n                json=data\n            )\n            return response.json()\n\ngateway = APIGateway()\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    return await gateway.forward_request(\"user\", f\"/users/{user_id}\", \"GET\")\n\n@app.post(\"/orders\")\nasync def create_order(order_data: dict):\n    return await gateway.forward_request(\"order\", \"/orders\", \"POST\", order_data)\n</code></pre>\n<h2>Monitoring and Observability</h2>\n<h3>Distributed Tracing with OpenTelemetry</h3>\n<pre><code class=\"language-python\">from opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\n# Configure tracing\ntrace.set_tracer_provider(TracerProvider())\ntracer = trace.get_tracer(__name__)\n\njaeger_exporter = JaegerExporter(\n    agent_host_name=\"localhost\",\n    agent_port=14268,\n)\n\nspan_processor = BatchSpanProcessor(jaeger_exporter)\ntrace.get_tracer_provider().add_span_processor(span_processor)\n\n# Use in your services\n@app.get(\"/users/{user_id}\")\nasync def get_user(user_id: int):\n    with tracer.start_as_current_span(\"get_user\") as span:\n        span.set_attribute(\"user.id\", user_id)\n        # Your service logic here\n        return {\"user_id\": user_id}\n</code></pre>\n<h2>Deployment with Docker</h2>\n<h3>Dockerfile for Python Services</h3>\n<pre><code class=\"language-dockerfile\">FROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>\n<h3>Docker Compose for Local Development</h3>\n<pre><code class=\"language-yaml\">version: '3.8'\n\nservices:\n  user-service:\n    build: ./user-service\n    ports:\n      - \"8001:8000\"\n    environment:\n      - DATABASE_URL=postgresql://user:password@db:5432/user_db\n    depends_on:\n      - db\n      - rabbitmq\n\n  order-service:\n    build: ./order-service\n    ports:\n      - \"8002:8000\"\n    environment:\n      - DATABASE_URL=postgresql://user:password@db:5432/order_db\n    depends_on:\n      - db\n      - rabbitmq\n\n  api-gateway:\n    build: ./api-gateway\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      - user-service\n      - order-service\n\n  rabbitmq:\n    image: rabbitmq:3-management\n    ports:\n      - \"5672:5672\"\n      - \"15672:15672\"\n\n  db:\n    image: postgres:13\n    environment:\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\nvolumes:\n  postgres_data:\n</code></pre>\n<h2>Best Practices</h2>\n<ol>\n<li><strong>Service Boundaries</strong>: Define clear service boundaries based on business capabilities</li>\n<li><strong>Data Consistency</strong>: Use eventual consistency and saga patterns for distributed transactions</li>\n<li><strong>Error Handling</strong>: Implement circuit breakers and retry mechanisms</li>\n<li><strong>Security</strong>: Use API keys, JWT tokens, and proper authentication</li>\n<li><strong>Testing</strong>: Write comprehensive tests for each service and integration tests</li>\n<li><strong>Documentation</strong>: Maintain clear API documentation for each service</li>\n</ol>\n<h2>Conclusion</h2>\n<p>Building scalable microservices with Python and FastAPI requires careful planning and implementation. By following the patterns and practices outlined in this guide, you can create a robust, maintainable microservices architecture that can scale with your business needs.</p>\n<p>Remember to start simple and gradually add complexity as your system grows. Monitor your services closely and be prepared to refactor as you learn more about your domain and requirements.</p>\n"
  }
]

// Get featured blog posts (top 3)
export const featuredBlogPosts = allBlogPosts.slice(0, 3)

export default {
  allBlogPosts,
  featuredBlogPosts,
}
